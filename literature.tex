\chapter{Literature review}
\label{chp:lit-review}
In this chapter, we give a high-level overview of probabilistic modeling, Bayesian inference, and NN distribution representation. We first describe discriminative and generative models, and why latent-variable generative models are of special interest in probabilistic machine learning. We then explain the three different types of inference methods used in our work---Markov chain Monte Carlo, amortized variational inference (VI), and expectation propagation (EP)---how each uses or is applied to NNs, and why they are well-suited for the applications given here. We finally discuss NN distribution representations, especially as they relate to amortized VI, drawing a distinction between factorization and parametrization, and giving a summary of methods used for constructing such representations.

\input{modeling}
\input{inference}
\input{representation}